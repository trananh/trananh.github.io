@Misc{Tran2014b,
  abstract      = {In this paper, we describe a simple strategy for mitigating variability in temporal data series by shifting focus onto long-term, frequency domain features that are less susceptible to variability.   We apply this method to the human action recognition task and demonstrate how working in the frequency domain can yield good recognition features for commonly used optical flow and articulated pose features, which are highly sensitive to small differences in motion, viewpoint, dynamic backgrounds, occlusion and other sources of variability.  We show how these frequency-based features can be used in combination with a simple forest classifier to achieve good and robust results on the popular KTH Actions dataset.},
  author        = {Tran, Anh  and  Guan, Jinyan and Pilantanakitti, Thanima  and  Cohen, Paul},
  title         = {Action Recognition in the Frequency Domain},
  year          = {2014},
  archivePrefix = {arXiv},
  eprint        = {1409.0908},
  primaryClass  = {cs.CV},
  url           = {http://arxiv.org/abs/1409.0908}
}